# Aerospike Deep Dive

Comprehensive technical guide to Aerospike, a high-performance distributed key-value NoSQL database. This document provides detailed technical information, configuration examples, operational procedures, and troubleshooting guides for Aerospike administrators and engineers.

> **For deployment strategies, decision frameworks, and high-level overviews, see the [Aerospike Mastery Series](https://thisiskushal31.github.io/blog/#/blog/aerospike-mastery-series) blog posts.**

## Table of Contents

### Getting Started
- [Overview](#overview)
- [Architecture](#architecture)
- [Hybrid Memory Architecture (HMA)](#hybrid-memory-architecture-hma)
- [Installation & Configuration](#installation--configuration)

### Data Model
- [Data Model Overview](#data-model-overview)
- [Namespaces](#namespaces)
- [Sets](#sets)
- [Records and Bins](#records-and-bins)
- [Data Types](#data-types)
- [Primary Index](#primary-index)
- [Secondary Indexes](#secondary-indexes)

### Operations
- [Basic Operations](#basic-operations)
- [Batch Operations](#batch-operations)
- [Query Operations](#query-operations)
- [Scan Operations](#scan-operations)
- [Aggregations](#aggregations)
- [User-Defined Functions (UDF)](#user-defined-functions-udf)

### Advanced Features
- [Transactions](#transactions)
- [Strong Consistency](#strong-consistency)
- [Durable Deletes](#durable-deletes)
- [Expressions](#expressions)
- [Expression Indexes](#expression-indexes)

### Clustering & Replication
- [Clustering Overview](#clustering-overview)
- [Data Distribution](#data-distribution)
- [Rack Awareness](#rack-awareness)
- [Consistency Modes](#consistency-modes)
- [Cross-Datacenter Replication (XDR)](#cross-datacenter-replication-xdr)

### Tools
- [AQL (Aerospike Query Language)](#aql-aerospike-query-language)
- [asadm (Administration Tool)](#asadm-administration-tool)
- [asbackup & asrestore](#asbackup--asrestore)
- [asbench (Benchmarking)](#asbench-benchmarking)
- [asinfo (Information Tool)](#asinfo-information-tool)

### Operations & Management
- [Monitoring](#monitoring)
- [Performance Optimization](#performance-optimization)
- [Backup & Recovery](#backup--recovery)
- [Security](#security)
- [Troubleshooting](#troubleshooting)

### Deployment
- [Linux Deployment](#linux-deployment)
- [Docker Deployment](#docker-deployment)
- [Kubernetes Deployment](#kubernetes-deployment)
- [Cloud Deployments](#cloud-deployments)

### Use Cases & Patterns
- [Use Cases](#use-cases)
- [Design Patterns](#design-patterns)
- [Best Practices](#best-practices)
- [Resources](#resources)

---

## Overview

Aerospike is a distributed, high-performance NoSQL database designed for real-time applications with predictable sub-millisecond latency. It's optimized for both in-memory and flash storage, making it cost-effective for large-scale deployments.

According to the [Aerospike Documentation](https://aerospike.com/docs/), "Aerospike is a high-performance, distributed, NoSQL database designed for real-time applications requiring low latency and high availability." Aerospike's Hybrid Memory Architecture (HMA) combines the speed of in-memory databases with the durability and cost-effectiveness of disk-based storage.

### Key Features

- **Hybrid Memory Architecture (HMA)**: Hot data in RAM, cold data on SSD/HDD
- **Strong Consistency**: ACID transactions with configurable consistency levels
- **Automatic Failover**: High availability with zero downtime
- **Cross-Datacenter Replication (XDR)**: Multi-region support with conflict resolution
- **Predictable Performance**: Sub-millisecond latency at scale
- **Horizontal Scaling**: Linear scaling with cluster size
- **Multi-Model Support**: Key-value, document, and graph data models
- **Real-Time Analytics**: Built-in aggregation and query capabilities

### Use Cases

- **AdTech**: Real-time bidding, user profiling, ad targeting
- **Financial Services**: Fraud detection, risk assessment, real-time analytics
- **Telecommunications**: Customer data management, personalization
- **Gaming**: Leaderboards, player profiles, real-time scoring
- **IoT**: Time-series data, sensor data aggregation
- **E-commerce**: Shopping carts, session management, recommendations

## Architecture

### Core Components

- **Namespace**: Top-level container (similar to database in RDBMS)
- **Set**: Collection within namespace (similar to table)
- **Record**: Key-value pair with bins (fields)
- **Bin**: Field within a record (similar to column)
- **Node**: Individual server in cluster
- **Partition**: Data distribution unit (4096 partitions per namespace)
- **Replica**: Copy of partition for redundancy

### Cluster Architecture

Aerospike operates as a shared-nothing cluster:
- **No Single Point of Failure**: Each node is identical
- **Automatic Data Distribution**: Even distribution using consistent hashing
- **Self-Healing**: Automatic partition migration on node failure
- **Zero-Downtime Operations**: Add/remove nodes without downtime

### Network Architecture

Aerospike uses multiple network ports:
- **Service Port (3000)**: Client connections
- **Fabric Port (3001)**: Inter-node communication
- **Heartbeat Port (3002)**: Cluster health monitoring
- **Info Port (3003)**: Administrative commands

## Hybrid Memory Architecture (HMA)

Aerospike's Hybrid Memory Architecture optimizes performance and cost by intelligently managing data across different storage tiers.

### Storage Tiers

1. **DRAM (Primary Index)**
   - Stores primary index in memory
   - Enables O(1) key lookups
   - Fastest access path

2. **DRAM (Data)**
   - Hot data stored in memory
   - Configurable per namespace
   - Fastest data access

3. **SSD/HDD (Data)**
   - Cold data stored on persistent storage
   - Cost-effective for large datasets
   - Still provides low latency

### HMA Benefits

- **Cost-Effective**: Store large datasets without requiring all RAM
- **Predictable Performance**: Consistent latency regardless of data size
- **Automatic Tiering**: System manages data placement
- **Scalability**: Scale to petabytes without proportional RAM increase

### Configuration

```conf
namespace test {
    # Memory for hot data
    memory-size 4G
    
    # Data in memory (all data in RAM)
    data-in-memory true
    
    # Or use device storage (HMA)
    storage-engine device {
        device /dev/sdb
        data-in-memory false  # Data on SSD
        filesize 100G
        data-in-index true   # Index in memory
    }
}
```

## Installation & Configuration

### Linux Installation

```bash
# Ubuntu/Debian
wget -O aerospike-server.tgz 'https://www.aerospike.com/download/server/latest/artifact/ubuntu20'
tar -xzf aerospike-server.tgz
cd aerospike-server-*
sudo ./asinstall

# CentOS/RHEL
wget -O aerospike-server.tgz 'https://www.aerospike.com/download/server/latest/artifact/el7'
tar -xzf aerospike-server.tgz
cd aerospike-server-*
sudo ./asinstall

# Start service
sudo systemctl start aerospike
sudo systemctl enable aerospike
sudo systemctl status aerospike
```

### Docker Installation

```bash
# Run Aerospike container
docker run -d --name aerospike -p 3000-3003:3000-3003 aerospike/aerospike-server

# With custom configuration
docker run -d --name aerospike \
  -p 3000-3003:3000-3003 \
  -v /path/to/aerospike.conf:/etc/aerospike/aerospike.conf \
  aerospike/aerospike-server
```

### Configuration File

```conf
# /etc/aerospike/aerospike.conf

service {
    user root
    group root
    paxos-single-replica-limit 1
    service-threads 4
    transaction-queues 4
    transaction-threads-per-queue 4
    proto-fd-max 15000
    pidfile /var/run/aerospike/asd.pid
}

logging {
    file /var/log/aerospike/aerospike.log {
        context any info
        context transaction detail
        context query detail
    }
    
    console {
        context any info
    }
}

network {
    service {
        address any
        port 3000
    }
    
    heartbeat {
        mode mesh
        address any
        port 3002
        interval 150
        timeout 10
        mesh-seed-address-port 192.168.1.10 3002
        mesh-seed-address-port 192.168.1.11 3002
    }
    
    fabric {
        address any
        port 3001
    }
    
    info {
        address any
        port 3003
    }
}

namespace test {
    replication-factor 2
    memory-size 4G
    default-ttl 30d
    max-ttl 0  # No expiration
    
    storage-engine device {
        device /dev/sdb
        data-in-memory false
        file /opt/aerospike/data/test.dat
        filesize 100G
        data-in-index true
        index-stage-size 128M
        cold-start-empty false
    }
    
    # Strong consistency configuration
    strong-consistency true
}
```

## Data Model Overview

### Hierarchical Structure

```
Namespace (test)
  └── Set (users)
      └── Record (user:123)
          ├── Bin: name = "John Doe"
          ├── Bin: email = "john@example.com"
          ├── Bin: age = 30
          └── Bin: tags = ["developer", "aerospike"]
```

### Key Components

- **Namespace**: Logical database container
- **Set**: Logical grouping of records (optional)
- **Record**: Individual data item with unique key
- **Bin**: Field within a record
- **Metadata**: TTL, generation, last update time

## Namespaces

Namespaces are the top-level containers in Aerospike, similar to databases in RDBMS.

### Namespace Configuration

```conf
namespace test {
    replication-factor 2
    memory-size 4G
    default-ttl 30d
    
    storage-engine device {
        device /dev/sdb
        filesize 100G
    }
}
```

### Namespace Types

1. **Data Namespace**: Stores user data
2. **System Namespace**: Stores system metadata (internal)

## Sets

Sets are logical groupings within a namespace, similar to tables in RDBMS.

### Set Characteristics

- **Optional**: Records can exist without a set
- **Logical Grouping**: Used for organization and queries
- **No Schema**: Sets don't enforce schema
- **Indexing**: Secondary indexes are created on sets

### Set Usage

```python
# Records in a set
key = ('test', 'users', 'user123')  # namespace, set, primary_key
key = ('test', None, 'user123')     # No set (None or empty string)
```

## Records and Bins

### Record Structure

```python
{
    'key': ('test', 'users', 'user123'),
    'bins': {
        'name': 'John Doe',
        'email': 'john@example.com',
        'age': 30,
        'active': True
    },
    'metadata': {
        'ttl': 86400,        # Time to live in seconds
        'generation': 1,      # Update counter
        'last_update_time': 1609459200
    }
}
```

### Bin Operations

```python
# Write bins
client.put(key, {
    'name': 'John Doe',
    'email': 'john@example.com'
})

# Read specific bins
(key, metadata, bins) = client.get(key, ['name', 'email'])

# Read all bins
(key, metadata, bins) = client.get(key)
```

## Data Types

Aerospike supports various data types for bins:

### Primitive Types

- **String**: UTF-8 strings
- **Integer**: 32-bit and 64-bit integers
- **Double**: 64-bit floating point
- **Bytes (Blob)**: Binary data

### Complex Types

- **List**: Ordered collection of values
- **Map**: Key-value pairs (dictionary)
- **GeoJSON**: Geospatial data

### Data Type Examples

```python
# String
client.put(key, {'name': 'John Doe'})

# Integer
client.put(key, {'age': 30, 'score': 1000})

# Double
client.put(key, {'price': 99.99, 'rating': 4.5})

# Bytes
client.put(key, {'image': bytearray([0x89, 0x50, 0x4E, 0x47])})

# List
client.put(key, {
    'tags': ['python', 'aerospike', 'nosql'],
    'scores': [100, 200, 300]
})

# Map
client.put(key, {
    'address': {
        'street': '123 Main St',
        'city': 'New York',
        'zip': '10001'
    },
    'preferences': {
        'theme': 'dark',
        'notifications': True
    }
})

# GeoJSON
client.put(key, {
    'location': {
        'type': 'Point',
        'coordinates': [-73.935242, 40.730610]
    }
})
```

## Primary Index

The primary index maps primary keys to data locations, enabling O(1) key lookups.

### Primary Index Characteristics

- **Always in Memory**: Stored in DRAM for fast access
- **Automatic**: Created automatically for all records
- **O(1) Lookup**: Constant time key access
- **No Configuration**: Managed automatically by Aerospike

### Primary Key Lookup

```python
# Fast primary key lookup
(key, metadata, bins) = client.get(('test', 'users', 'user123'))
```

## Secondary Indexes

Secondary indexes enable querying by bin values, not just primary keys.

### Index Types

1. **String Index**: For string bin values
2. **Numeric Index**: For integer and double bin values
3. **Geo2DSphere Index**: For GeoJSON data
4. **List Index**: For list elements
5. **Map Index**: For map keys/values
6. **Expression Index**: For computed values

### Creating Secondary Indexes

```python
# String index
try:
    client.index_string_create(
        'test',      # namespace
        'users',     # set
        'idx_email',  # index name
        'email',     # bin name
        aerospike.INDEX_TYPE_STRING
    )
except ex.IndexFoundError:
    pass  # Index already exists

# Numeric index
try:
    client.index_integer_create(
        'test',
        'users',
        'idx_age',
        'age',
        aerospike.INDEX_TYPE_NUMERIC
    )
except ex.IndexFoundError:
    pass

# Geo2DSphere index
try:
    client.index_geo2dsphere_create(
        'test',
        'users',
        'idx_location',
        'location'
    )
except ex.IndexFoundError:
    pass
```

### Querying with Secondary Indexes

```python
# Query by secondary index
query = client.query('test', 'users')
query.select('name', 'email')
query.where(predicates.equals('email', 'john@example.com'))

def print_result((key, metadata, bins)):
    print(f"Key: {key}, Bins: {bins}")

query.foreach(print_result)

# Range query
query = client.query('test', 'users')
query.where(predicates.between('age', 25, 35))
query.foreach(print_result)

# Geo query
query = client.query('test', 'users')
query.where(predicates.geo_within_radius(
    'location',
    -73.935242,  # longitude
    40.730610,   # latitude
    1000         # radius in meters
))
query.foreach(print_result)
```

## Basic Operations

### Python Client

```python
import aerospike

# Connect
config = {
    'hosts': [('127.0.0.1', 3000)]
}
client = aerospike.client(config).connect()

# Write record
key = ('test', 'users', 'user123')
client.put(key, {
    'name': 'John Doe',
    'email': 'john@example.com',
    'age': 30
})

# Read record
(key, metadata, bins) = client.get(key)
print(bins)

# Update record (partial)
client.put(key, {
    'age': 31,
    'last_login': '2024-01-01'
})

# Read specific bins
(key, metadata, bins) = client.get(key, ['name', 'email'])

# Check existence
exists = client.exists(key)

# Delete record
client.remove(key)

# Increment bin
client.increment(key, 'age', 1)
client.increment(key, 'score', 10)

# Append to string bin
client.append(key, 'log', 'new entry\n')

# Prepend to string bin
client.prepend(key, 'log', 'prefix: ')

# Touch (update TTL without reading)
client.touch(key, ttl=3600)
```

### Java Client

```java
import com.aerospike.client.*;
import com.aerospike.client.policy.*;

// Connect
Host[] hosts = new Host[] {
    new Host("127.0.0.1", 3000)
};
AerospikeClient client = new AerospikeClient(null, hosts);

// Write record
Key key = new Key("test", "users", "user123");
Bin bin1 = new Bin("name", "John Doe");
Bin bin2 = new Bin("email", "john@example.com");
Bin bin3 = new Bin("age", 30);
client.put(null, key, bin1, bin2, bin3);

// Read record
Record record = client.get(null, key);
System.out.println(record.bins);

// Update record
Bin bin4 = new Bin("age", 31);
client.put(null, key, bin4);

// Increment
client.add(null, key, new Bin("age", 1));
client.add(null, key, new Bin("score", 10));

// Delete record
client.delete(null, key);

// Touch
client.touch(null, key);
```

## Batch Operations

Batch operations allow reading/writing multiple records efficiently.

### Batch Read

```python
# Batch get
keys = [
    ('test', 'users', 'user1'),
    ('test', 'users', 'user2'),
    ('test', 'users', 'user3')
]
records = client.get_many(keys)

for (key, metadata, bins) in records:
    if bins:  # Record exists
        print(f"Key: {key}, Bins: {bins}")
```

### Batch Write

```python
# Batch write
keys = [('test', 'users', f'user{i}') for i in range(100)]
records = [
    {'name': f'User {i}', 'age': 20 + i}
    for i in range(100)
]

for key, record in zip(keys, records):
    client.put(key, record)
```

### Batch Operations Policy

```python
from aerospike import exception as ex

# Batch policy
policy = {
    'max_retries': 2,
    'sleep_between_retries': 0.001,
    'timeout': 1000
}

records = client.get_many(keys, policy)
```

## Query Operations

Queries use secondary indexes to find records matching criteria.

### Basic Query

```python
# Query all records in set
query = client.query('test', 'users')
query.select('name', 'email')

def print_result((key, metadata, bins)):
    print(bins)

query.foreach(print_result)
```

### Query with Predicates

```python
from aerospike import predicates

# Equality
query = client.query('test', 'users')
query.where(predicates.equals('email', 'john@example.com'))
query.foreach(print_result)

# Range
query = client.query('test', 'users')
query.where(predicates.between('age', 25, 35))
query.foreach(print_result)

# Greater than
query = client.query('test', 'users')
query.where(predicates.greater_than('age', 30))
query.foreach(print_result)

# Less than
query = client.query('test', 'users')
query.where(predicates.less_than('age', 30))
query.foreach(print_result)

# Contains (for lists)
query = client.query('test', 'users')
query.where(predicates.contains('tags', aerospike.INDEX_TYPE_STRING, 'python'))
query.foreach(print_result)

# Geo within radius
query = client.query('test', 'users')
query.where(predicates.geo_within_radius('location', -73.935242, 40.730610, 1000))
query.foreach(print_result)
```

### Query Policies

```python
# Query policy
policy = {
    'max_retries': 2,
    'timeout': 1000,
    'short_query': True  # For small result sets
}

query = client.query('test', 'users')
query.select('name', 'email')
query.where(predicates.equals('email', 'john@example.com'))
query.foreach(print_result, policy)
```

## Scan Operations

Scans iterate through all records in a namespace or set without using indexes.

### Basic Scan

```python
# Scan all records in set
scan = client.scan('test', 'users')
scan.select('name', 'email')

def print_result((key, metadata, bins)):
    print(bins)

scan.foreach(print_result)
```

### Scan Policies

```python
# Scan policy
policy = {
    'max_retries': 2,
    'timeout': 1000,
    'scan_percent': 100  # Percentage of data to scan
}

scan = client.scan('test', 'users')
scan.foreach(print_result, policy)
```

### Parallel Scans

```python
# Parallel scan (faster for large datasets)
scan = client.scan('test', 'users')
scan.parallel(True)  # Enable parallel scanning
scan.foreach(print_result)
```

## Aggregations

Aggregations perform computations on query results using User-Defined Functions (UDF).

### Built-in Aggregations

```python
# Count records
query = client.query('test', 'users')
query.where(predicates.between('age', 25, 35))
count = query.results()  # Returns list of records
print(f"Count: {len(count)}")
```

### UDF Aggregations

```lua
-- count_users.lua
function count_users(stream)
    local function count(rec)
        return 1
    end
    
    return stream : map(count) : reduce(function(a, b) return a + b end)
end

-- sum_age.lua
function sum_age(stream)
    local function get_age(rec)
        return rec['age']
    end
    
    return stream : map(get_age) : reduce(function(a, b) return a + b end)
end

-- avg_age.lua
function avg_age(stream)
    local function get_age(rec)
        return rec['age']
    end
    
    local function sum(a, b)
        return a + b
    end
    
    local function count(a, b)
        return a + 1
    end
    
    local sum_result = stream : map(get_age) : reduce(sum)
    local count_result = stream : map(get_age) : reduce(count)
    
    if count_result > 0 then
        return sum_result / count_result
    else
        return 0
    end
end
```

### Using Aggregations

```python
# Register UDF
client.udf_put('count_users.lua')

# Execute aggregation
query = client.query('test', 'users')
query.where(predicates.between('age', 25, 35))
result = query.apply('count_users', 'count_users')
print(f"Count: {result}")

# Multiple aggregations
query = client.query('test', 'users')
sum_result = query.apply('sum_age', 'sum_age')
avg_result = query.apply('avg_age', 'avg_age')
print(f"Sum: {sum_result}, Avg: {avg_result}")
```

## User-Defined Functions (UDF)

UDFs allow server-side processing using Lua scripts.

### UDF Types

1. **Record UDFs**: Operate on single records
2. **Stream UDFs**: Operate on query/scan streams (aggregations)

### Record UDF Example

```lua
-- update_score.lua
function update_score(rec, increment)
    local current_score = rec['score'] or 0
    rec['score'] = current_score + increment
    rec['last_updated'] = os.time()
    aerospike:update(rec)
    return rec['score']
end
```

### Using Record UDFs

```python
# Register UDF
client.udf_put('update_score.lua')

# Execute UDF
key = ('test', 'users', 'user123')
result = client.apply(key, 'update_score', 'update_score', [10])
print(f"New score: {result}")
```

### Stream UDF Example

```lua
-- top_users.lua
function top_users(stream, limit)
    local function get_score(rec)
        return rec['score']
    end
    
    local function compare(a, b)
        return a > b
    end
    
    return stream : map(get_score) : aggregate({}, function(acc, score)
        table.insert(acc, score)
        table.sort(acc, compare)
        if #acc > limit then
            table.remove(acc)
        end
        return acc
    end)
end
```

## Transactions

Aerospike supports ACID transactions for strong consistency.

### Transaction Characteristics

- **ACID Compliance**: Atomicity, Consistency, Isolation, Durability
- **Distributed**: Works across cluster nodes
- **Configurable**: Choose consistency level per operation
- **Performance**: Optimized for high throughput

### Transaction Operations

```python
# Read-Modify-Write (atomic)
key = ('test', 'users', 'user123')

# Atomic increment
client.increment(key, 'counter', 1)

# Atomic append
client.append(key, 'log', 'new entry\n')

# Atomic prepend
client.prepend(key, 'log', 'prefix: ')

# Read with generation check
policy = {
    'gen': aerospike.POLICY_GEN_EQ,  # Generation must match
    'gen_value': 5
}
try:
    (key, metadata, bins) = client.get(key, policy=policy)
except ex.RecordGenerationError:
    print("Record was modified")
```

### Transaction Policies

```python
# Write policy with generation
write_policy = {
    'gen': aerospike.POLICY_GEN_EQ,
    'gen_value': 5,
    'commit_level': aerospike.POLICY_COMMIT_LEVEL_ALL
}

client.put(key, {'age': 31}, policy=write_policy)

# Read policy with consistency
read_policy = {
    'consistency_level': aerospike.POLICY_CONSISTENCY_ALL
}

(key, metadata, bins) = client.get(key, policy=read_policy)
```

## Strong Consistency

Aerospike provides strong consistency guarantees when configured.

### Consistency Levels

1. **ALL**: Read from all replicas, write to all replicas
2. **ONE**: Read from one replica, write to one replica (eventual consistency)
3. **MASTER**: Read from master, write to master

### Enabling Strong Consistency

```conf
namespace test {
    strong-consistency true
    replication-factor 2
}
```

### Using Strong Consistency

```python
# Strong consistency read
read_policy = {
    'consistency_level': aerospike.POLICY_CONSISTENCY_ALL
}

(key, metadata, bins) = client.get(key, policy=read_policy)

# Strong consistency write
write_policy = {
    'commit_level': aerospike.POLICY_COMMIT_LEVEL_ALL
}

client.put(key, {'age': 31}, policy=write_policy)
```

## Durable Deletes

Durable deletes ensure deleted records are not resurrected after node failures.

### Enabling Durable Deletes

```conf
namespace test {
    durable-deletes true
}
```

### Using Durable Deletes

```python
# Durable delete
delete_policy = {
    'durable_delete': True
}

client.remove(key, policy=delete_policy)
```

## Expressions

Expressions allow filtering and transformation at the server side.

### Expression Examples

```python
from aerospike_helpers import expressions as exp

# Filter expression
filter_exp = exp.And(
    exp.GE(exp.IntBin("age"), 25),
    exp.LE(exp.IntBin("age"), 35)
)

# Query with expression
query = client.query('test', 'users')
query.expressions = filter_exp
query.foreach(print_result)

# Update expression
update_exp = exp.Let(
    exp.Def("age", exp.IntBin("age")),
    exp.Def("new_age", exp.Add(exp.Var("age"), 1)),
    exp.Put(exp.IntBin("age"), exp.Var("new_age"))
)

# Apply expression
policy = {
    'expressions': update_exp
}
client.put(key, {}, policy=policy)
```

## Expression Indexes

Expression indexes create indexes on computed values.

### Creating Expression Index

```python
# Create expression index
exp_index = exp.Let(
    exp.Def("full_name", exp.Concat(
        exp.StringBin("first_name"),
        exp.Val(" "),
        exp.StringBin("last_name")
    )),
    exp.Var("full_name")
)

client.index_create(
    'test',
    'users',
    'idx_full_name',
    exp_index,
    aerospike.INDEX_TYPE_STRING
)

# Query using expression index
query = client.query('test', 'users')
query.where(predicates.equals('full_name', 'John Doe'))
query.foreach(print_result)
```

## Clustering Overview

Aerospike clusters distribute data across multiple nodes for scalability and availability.

### Cluster Components

- **Nodes**: Individual servers in cluster
- **Partitions**: Data distribution units (4096 per namespace)
- **Replicas**: Copies of partitions for redundancy
- **Heartbeat**: Health monitoring between nodes

### Cluster Formation

```conf
# Node 1
network {
    heartbeat {
        mode mesh
        mesh-seed-address-port 192.168.1.10 3002
        mesh-seed-address-port 192.168.1.11 3002
    }
}

# Node 2
network {
    heartbeat {
        mode mesh
        mesh-seed-address-port 192.168.1.10 3002
        mesh-seed-address-port 192.168.1.11 3002
    }
}
```

## Data Distribution

Aerospike uses consistent hashing to distribute data across nodes.

### Partition Distribution

- **4096 Partitions**: Each namespace has 4096 partitions
- **Hash Function**: MD5 hash of primary key
- **Even Distribution**: Partitions evenly distributed across nodes
- **Automatic Rebalancing**: Partitions migrate when nodes added/removed

### Partition Ownership

```bash
# Check partition distribution
asinfo -v "partitions"

# Check partition ownership
asinfo -v "partitions/test"
```

## Rack Awareness

Rack awareness ensures replicas are placed on different racks for fault tolerance.

### Rack Configuration

```conf
# Node in rack 1
namespace test {
    rack-id 1
}

# Node in rack 2
namespace test {
    rack-id 2
}
```

### Rack-Aware Replication

- Replicas placed on different racks
- Prevents data loss from rack failures
- Automatic failover across racks

## Consistency Modes

Aerospike supports different consistency modes for different use cases.

### Consistency Levels

1. **Strong Consistency**: All replicas must agree
2. **Eventual Consistency**: One replica sufficient
3. **Master Consistency**: Only master replica

### Configuration

```conf
namespace test {
    strong-consistency true  # Enable strong consistency
    replication-factor 2
}
```

## Cross-Datacenter Replication (XDR)

XDR enables replication between clusters in different datacenters.

### XDR Configuration

```conf
# Source cluster
xdr {
    enable-xdr true
    xdr-namedpipe-path /tmp/xdr_pipe
    
    datacenter DC1 {
        dc-node-address-port 192.168.1.10 3000
        dc-node-address-port 192.168.1.11 3000
    }
    
    datacenter DC2 {
        dc-node-address-port 192.168.2.10 3000
        dc-node-address-port 192.168.2.11 3000
    }
}

# Destination cluster
namespace test {
    xdr {
        datacenter DC1 {
            dc-node-address-port 192.168.1.10 3000
        }
    }
}
```

### XDR Features

- **Multi-Datacenter**: Replicate to multiple datacenters
- **Conflict Resolution**: Automatic conflict resolution
- **Filtering**: Replicate specific namespaces/sets
- **Compression**: Optional compression for efficiency

## AQL (Aerospike Query Language)

AQL is a command-line tool for interacting with Aerospike.

### Basic AQL Commands

```bash
# Connect to cluster
aql -h 127.0.0.1 -p 3000

# Show namespaces
SHOW NAMESPACES

# Show sets
SHOW SETS test

# Insert record
INSERT INTO test.users (PK, name, email, age) VALUES ('user123', 'John Doe', 'john@example.com', 30)

# Select record
SELECT * FROM test.users WHERE PK = 'user123'

# Update record
UPDATE test.users SET age = 31 WHERE PK = 'user123'

# Delete record
DELETE FROM test.users WHERE PK = 'user123'

# Query with secondary index
SELECT * FROM test.users WHERE email = 'john@example.com'

# Aggregation
AGGREGATE count_users.count_users() ON test.users WHERE age BETWEEN 25 AND 35
```

### AQL Examples

```bash
# Batch insert
INSERT INTO test.users (PK, name, email, age) VALUES
  ('user1', 'User 1', 'user1@example.com', 25),
  ('user2', 'User 2', 'user2@example.com', 30),
  ('user3', 'User 3', 'user3@example.com', 35)

# Select with conditions
SELECT name, email FROM test.users WHERE age >= 30

# Count records
SELECT COUNT(*) FROM test.users
```

## asadm (Administration Tool)

asadm is an interactive administration tool for managing Aerospike clusters.

### Starting asadm

```bash
# Connect to cluster
asadm

# Connect to specific node
asadm -h 127.0.0.1 -p 3000
```

### asadm Commands

```bash
# Show cluster information
show cluster

# Show namespaces
show namespaces

# Show sets
show sets test

# Show statistics
show statistics

# Show configuration
show config

# Show latency
show latency

# Show distribution
show distribution

# Manage indexes
manage indexes

# Manage UDFs
manage udf

# Exit
exit
```

## asbackup & asrestore

asbackup and asrestore are tools for backing up and restoring Aerospike data.

### Backup

```bash
# Backup namespace
asbackup --host 127.0.0.1 --namespace test --directory /backup/test

# Backup specific set
asbackup --host 127.0.0.1 --namespace test --set users --directory /backup/users

# Backup to S3
asbackup --host 127.0.0.1 --namespace test --directory s3://bucket/backup

# Parallel backup
asbackup --host 127.0.0.1 --namespace test --directory /backup/test --parallel 4
```

### Restore

```bash
# Restore namespace
asrestore --host 127.0.0.1 --namespace test --directory /backup/test

# Restore from S3
asrestore --host 127.0.0.1 --namespace test --directory s3://bucket/backup

# Parallel restore
asrestore --host 127.0.0.1 --namespace test --directory /backup/test --parallel 4
```

## asbench (Benchmarking)

asbench is a benchmarking tool for testing Aerospike performance.

### Benchmark Examples

```bash
# Write benchmark
asbench -h 127.0.0.1 -p 3000 -n test -s users -k 1000000 -o I -w I

# Read benchmark
asbench -h 127.0.0.1 -p 3000 -n test -s users -k 1000000 -o I -w R

# Mixed workload
asbench -h 127.0.0.1 -p 3000 -n test -s users -k 1000000 -o I -w RU,30

# Latency test
asbench -h 127.0.0.1 -p 3000 -n test -s users -k 1000000 -o I -w R --latency
```

## asinfo (Information Tool)

asinfo retrieves information from Aerospike nodes.

### asinfo Examples

```bash
# Cluster statistics
asinfo -v "statistics"

# Namespace statistics
asinfo -v "namespace/test"

# Node information
asinfo -v "node"

# Build information
asinfo -v "build"

# Configuration
asinfo -v "get-config:context=namespace;id=test"
```

## Monitoring

### Key Metrics

- **Latency**: P50, P95, P99 percentiles
- **Throughput**: Operations per second
- **Memory Usage**: RAM and disk usage
- **Replication Lag**: Delay between replicas
- **Error Rates**: Failed operations

### Monitoring Tools

```bash
# Real-time statistics
asinfo -v "statistics"

# Latency histogram
asinfo -v "latency:"

# Namespace statistics
asinfo -v "namespace/test"

# Node health
asinfo -v "health"
```

### Monitoring with asadm

```bash
# Show statistics
show statistics

# Show latency
show latency

# Show distribution
show distribution

# Show configuration
show config
```

## Performance Optimization

### Memory Configuration

```conf
namespace test {
    # Memory for hot data
    memory-size 4G
    
    # Data in memory
    data-in-memory true
    
    # Or use HMA
    storage-engine device {
        device /dev/sdb
        data-in-memory false
        filesize 100G
        data-in-index true
        index-stage-size 128M
    }
}
```

### Index Optimization

```conf
namespace test {
    storage-engine device {
        data-in-index true      # Keep index in memory
        index-stage-size 128M   # Index staging size
    }
}
```

### Service Threads

```conf
service {
    service-threads 4
    transaction-queues 4
    transaction-threads-per-queue 4
}
```

### Best Practices

1. **Use Appropriate Data Types**: Smaller types = less memory
2. **Set TTL**: Automatically expire old data
3. **Batch Operations**: Group operations for efficiency
4. **Secondary Indexes**: Use sparingly (impact write performance)
5. **Connection Pooling**: Reuse connections
6. **Avoid Scans**: Use queries with secondary indexes when possible
7. **Monitor Latency**: Track P95 and P99 percentiles
8. **Optimize Bin Names**: Shorter names save memory

## Backup & Recovery

### Backup Strategies

1. **asbackup**: Full namespace backup
2. **Snapshot**: Point-in-time backup
3. **XDR**: Cross-datacenter replication as backup

### Backup Schedule

```bash
# Daily backup script
#!/bin/bash
DATE=$(date +%Y%m%d)
asbackup --host 127.0.0.1 --namespace test --directory /backup/test_$DATE
```

### Recovery Procedures

```bash
# Restore from backup
asrestore --host 127.0.0.1 --namespace test --directory /backup/test_20240101

# Verify restore
aql -h 127.0.0.1 -e "SELECT COUNT(*) FROM test.users"
```

## Security

### Authentication

```conf
# Enable security
security {
    enable-security true
}

# Create user
asinfo -v "user-admin:admin;user-create:user=admin,password=admin,roles=sys-admin"
```

### Access Control

```conf
# Define roles
security {
    enable-security true
    
    role sys-admin {
        privileges read-write
        whitelist *
    }
    
    role user-admin {
        privileges user-admin
        whitelist *
    }
    
    role data-admin {
        privileges read-write
        whitelist test.*
    }
}
```

### TLS/SSL

```conf
network {
    tls {
        name test-tls
        cert-file /etc/aerospike/certs/server.crt
        key-file /etc/aerospike/certs/server.key
        ca-file /etc/aerospike/certs/ca.crt
    }
    
    service {
        tls-name test-tls
    }
}
```

## Troubleshooting

### Common Issues

**High Latency:**
```bash
# Check latency
asinfo -v "latency:"

# Check memory
asinfo -v "namespace/test"

# Check disk I/O
iostat -x 1
```

**Memory Issues:**
```bash
# Check memory usage
asinfo -v "namespace/test"

# Check eviction
asinfo -v "namespace/test" | grep evict
```

**Replication Issues:**
```bash
# Check cluster health
asinfo -v "cluster"

# Check replication lag
asinfo -v "namespace/test" | grep replication
```

**Connection Issues:**
```bash
# Check connections
asinfo -v "statistics" | grep connections

# Check network
netstat -an | grep 3000
```

## Linux Deployment

### Installation

```bash
# Download and install
wget -O aerospike-server.tgz 'https://www.aerospike.com/download/server/latest/artifact/ubuntu20'
tar -xzf aerospike-server.tgz
cd aerospike-server-*
sudo ./asinstall

# Start service
sudo systemctl start aerospike
sudo systemctl enable aerospike
```

### Configuration

Edit `/etc/aerospike/aerospike.conf` and restart service:

```bash
sudo systemctl restart aerospike
```

## Docker Deployment

### Basic Docker Run

```bash
docker run -d --name aerospike \
  -p 3000-3003:3000-3003 \
  aerospike/aerospike-server
```

### Docker with Custom Config

```bash
docker run -d --name aerospike \
  -p 3000-3003:3000-3003 \
  -v /path/to/aerospike.conf:/etc/aerospike/aerospike.conf \
  -v /path/to/data:/opt/aerospike/data \
  aerospike/aerospike-server
```

### Docker Compose

```yaml
version: '3'
services:
  aerospike:
    image: aerospike/aerospike-server
    ports:
      - "3000-3003:3000-3003"
    volumes:
      - ./aerospike.conf:/etc/aerospike/aerospike.conf
      - ./data:/opt/aerospike/data
    environment:
      - AEROSPIKE_NAMESPACE=test
```

## Kubernetes Deployment

### Using Aerospike Kubernetes Operator (AKO)

```bash
# Install AKO
kubectl apply -f https://raw.githubusercontent.com/aerospike/aerospike-kubernetes-operator/master/deploy/operator.yaml

# Deploy cluster
kubectl apply -f aerospike-cluster.yaml
```

### Cluster YAML

```yaml
apiVersion: asdb.aerospike.com/v1
kind: AerospikeCluster
metadata:
  name: aerospike-cluster
spec:
  size: 3
  image: aerospike/aerospike-server-enterprise:7.0.0
  storage:
    volumes:
      - name: workdir
        aerospike:
          path: /opt/aerospike/data
        source:
          persistentVolume:
            size: 100Gi
            storageClass: fast-ssd
  aerospikeConfig:
    service:
      service-threads: 4
    namespace test:
      replication-factor: 2
      memory-size: 4G
      storage-engine:
        type: device
        devices:
          - /dev/sdb
```

## Cloud Deployments

### AWS Deployment

- Use EC2 instances with EBS volumes
- Configure security groups for ports 3000-3003
- Use placement groups for low latency
- Consider using AWS Marketplace image

### Azure Deployment

- Use VM instances with managed disks
- Configure network security groups
- Use availability sets for high availability
- Consider proximity placement groups

### GCP Deployment

- Use Compute Engine instances with persistent disks
- Configure firewall rules
- Use instance groups for scaling
- Consider using GCP Marketplace image

## Use Cases

### AdTech

- **Real-time Bidding**: Fast user profile lookups
- **User Profiling**: Store and query user attributes
- **Ad Targeting**: Real-time ad selection

### Financial Services

- **Fraud Detection**: Real-time transaction analysis
- **Risk Assessment**: Fast risk scoring
- **Customer 360**: Unified customer profiles

### Gaming

- **Leaderboards**: Real-time scoring and rankings
- **Player Profiles**: Fast player data access
- **Session Management**: Game session storage

### IoT

- **Time-Series Data**: Sensor data storage
- **Real-time Analytics**: Fast aggregation queries
- **Device Management**: Device state tracking

## Design Patterns

### Key Design

- Use meaningful, unique keys
- Include namespace and set in key structure
- Consider key distribution for even load

### Bin Design

- Use appropriate data types
- Keep bin names short
- Group related data in maps/lists

### Namespace Design

- Use namespaces for data isolation
- Separate by access patterns
- Consider replication requirements

### Set Design

- Use sets for logical grouping
- Consider query patterns
- Use for secondary index organization

## Best Practices

1. **Namespace Design**: Use namespaces for data isolation
2. **Set Design**: Use sets for logical grouping
3. **Key Design**: Use meaningful, unique keys
4. **TTL**: Set appropriate time-to-live
5. **Replication**: Use replication-factor 2 or 3
6. **Monitoring**: Monitor performance and resource usage
7. **Backup**: Regular backups of critical data
8. **Security**: Enable authentication and access control
9. **Capacity Planning**: Plan for growth
10. **Testing**: Test failover and recovery procedures
11. **Indexes**: Use secondary indexes sparingly
12. **Connection Pooling**: Reuse connections
13. **Batch Operations**: Group operations when possible
14. **Avoid Scans**: Use queries with indexes
15. **Monitor Latency**: Track P95 and P99 percentiles

## Resources

### Official Documentation
- [Aerospike Documentation](https://aerospike.com/docs/)
- [Aerospike Academy](https://www.aerospike.com/academy/)
- [Aerospike Blog](https://www.aerospike.com/blog/)

### Client Libraries
- [Python Client](https://github.com/aerospike/aerospike-client-python)
- [Java Client](https://github.com/aerospike/aerospike-client-java)
- [Node.js Client](https://github.com/aerospike/aerospike-client-nodejs)
- [Go Client](https://github.com/aerospike/aerospike-client-go)

### Tools
- [AQL Documentation](https://docs.aerospike.com/tools/aql)
- [asadm Documentation](https://docs.aerospike.com/tools/asadm)
- [asbackup Documentation](https://docs.aerospike.com/tools/asbackup)

### Community
- [Aerospike Forum](https://discuss.aerospike.com/)
- [GitHub](https://github.com/aerospike)
- [Stack Overflow - Aerospike](https://stackoverflow.com/questions/tagged/aerospike)

---

*This comprehensive guide covers Aerospike fundamentals, advanced features, and best practices. For deployment strategies and decision frameworks, refer to the [Aerospike Mastery Series](https://thisiskushal31.github.io/blog/#/blog/aerospike-mastery-series) blog posts.*
